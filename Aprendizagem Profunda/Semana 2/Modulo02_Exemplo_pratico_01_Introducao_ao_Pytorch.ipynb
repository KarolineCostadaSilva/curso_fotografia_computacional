{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nne_DFrByoPA"
      },
      "source": [
        "# Introdução ao Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z66PPosgyoPD"
      },
      "source": [
        "O Pytorch é uma *framework* para aplicações de modelos de redes neurais. Toda sua documentação pode ser vista no site oficial do [Pytorch](https://pytorch.org/).\n",
        "\n",
        "Esse tutorial apresenta alguns passos introdutórios para produção dos modelos de Deep Learning que serão aplicados e foi baseado no tutorial oferecido pelo [Pytorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
        "O tutorial tem os seguintes passos:\n",
        "- Tensores\n",
        "- Datasets e Dataloader\n",
        "- Construção do Modelo\n",
        "- Autograd\n",
        "- Treinamento do modelo\n",
        "- Salvamento e Carregamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmWd-4XjyoPE"
      },
      "source": [
        "Primeiro, importa-se as bibliotecas necessárias para esse tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFjiLFxoyoPE"
      },
      "source": [
        "## Tensores\n",
        "\n",
        "Tensores são a estrutura de dados especializadas para os calculos dos parâmetros desejados dos modelos. Nesta sessão serão descritos como criar os tensores e algumas operações básicas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KeQMnSzEyoPF"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas necessárias para essa seção\n",
        "import torch\n",
        "import numpy as numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40PfMrRNyoPG"
      },
      "source": [
        "### Inicialização de Tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3irqHRmfyoPG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GNc4d6cfyoPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2c1eb0-ebd1-4394-ba77-00332b46c325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores a partir de uma lista: tensor([[1, 2],\n",
            "        [2, 4]])\n",
            "\n",
            "\n",
            "Valores a partir partir de um numpy array: [[1, 2], [2, 4]]\n",
            "\n",
            "\n",
            "Valores unitários a partir de um tensor: tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "\n",
            "\n",
            "Valores aleatórios a partir de um tensor: tensor([[0.0576, 0.8467],\n",
            "        [0.6413, 0.3519]])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inicialização do Tensor a partir de uma lista\n",
        "data = [[1, 2], [2, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Valores a partir de uma lista: {x_data}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Inicialização do Tensor a partir de um numpy array\n",
        "np_array = [[1, 2], [2, 4]]\n",
        "x_np = torch.tensor(np_array)\n",
        "print(f\"Valores a partir partir de um numpy array: {np_array}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Inicialização do Tensor a partir de outro tensor.\n",
        "# Valores unitários\n",
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Valores unitários a partir de um tensor: {x_ones}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Valores aleatórios\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"Valores aleatórios a partir de um tensor: {x_rand}\", end=\"\\n\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EV_WD0Q0yoPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e3f24e-7d52-4507-9dc2-c8bd3fd7022e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensão do Tensor: torch.Size([3, 4])\n",
            "Tipo de dado do Tensor: torch.float32\n",
            "Device em que o Tensor está armazenado: cpu\n"
          ]
        }
      ],
      "source": [
        "# Alguns atributos do tensor\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Dimensão do Tensor: {tensor.shape}\")\n",
        "print(f\"Tipo de dado do Tensor: {tensor.dtype}\")\n",
        "print(f\"Device em que o Tensor está armazenado: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1TMyr3QyoPH"
      },
      "source": [
        "### Operações com Tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4N7PHXWiyoPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1472204a-a027-44b6-88fb-20c0b077ab0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeira linha: tensor([1., 1., 1., 1.])\n",
            "Primeira coluna: tensor([1., 1., 1., 1.])\n",
            "Última coluna: tensor([1., 1., 1., 1.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Indexing e Slicing:\n",
        "tensor = torch.ones(4, 4)\n",
        "print(f\"Primeira linha: {tensor[0]}\")\n",
        "print(f\"Primeira coluna: {tensor[:, 0]}\")\n",
        "print(f\"Última coluna: {tensor[..., -1]}\")\n",
        "\n",
        "tensor[:, 1] = 0\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H6hjNrWGyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7d0cdf-f2c8-4db2-f0d2-42316a0ad7a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Concatenação de Tensores:\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HWdDVlWjyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b95863-fe59-4748-c152-c9764a7dbc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5368, 0.8708, 0.1021, 0.6222],\n",
            "        [0.0849, 0.1673, 0.0500, 0.2403],\n",
            "        [0.1412, 0.6837, 0.5494, 0.8446]])\n",
            "tensor([[0.6032, 0.8567, 0.3186, 0.9828],\n",
            "        [0.4714, 0.7255, 0.5049, 0.2427],\n",
            "        [0.8336, 0.7162, 0.8807, 0.5329]])\n"
          ]
        }
      ],
      "source": [
        "# Operações aritméticas\n",
        "tensor1 = torch.rand(3, 4)\n",
        "tensor2 = torch.rand_like(tensor1)\n",
        "\n",
        "print(tensor1)\n",
        "print(tensor2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EQdfOrZByoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496092dd-a865-44d1-a7be-32c628ebb218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.1400, 1.7274, 0.4207, 1.6050],\n",
            "        [0.5563, 0.8927, 0.5549, 0.4830],\n",
            "        [0.9748, 1.3999, 1.4302, 1.3775]])\n",
            "tensor([[-0.0664,  0.0141, -0.2165, -0.3607],\n",
            "        [-0.3865, -0.5582, -0.4549, -0.0023],\n",
            "        [-0.6924, -0.0325, -0.3313,  0.3117]])\n"
          ]
        }
      ],
      "source": [
        "# Soma e Subtração (opera elemento a elemento)\n",
        "sum_tensor = tensor1 + tensor2\n",
        "sub_tensor = tensor1 - tensor2\n",
        "\n",
        "print(sum_tensor)\n",
        "print(sub_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r5Q-Lzn4yoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81591c91-972c-4a7c-8dd2-ca35ea0b22ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3238, 0.7459, 0.0325, 0.6115],\n",
            "        [0.0400, 0.1214, 0.0252, 0.0583],\n",
            "        [0.1177, 0.4897, 0.4839, 0.4501]])\n",
            "tensor([[0.8899, 1.0165, 0.3205, 0.6330],\n",
            "        [0.1801, 0.2306, 0.0990, 0.9903],\n",
            "        [0.1694, 0.9547, 0.6239, 1.5849]])\n"
          ]
        }
      ],
      "source": [
        "# Multiplicação e Divisão (opera elemento a elemento)\n",
        "mul_tensor = tensor1 * tensor2  ## ou torch.mul(tensor1, tensor2)\n",
        "div_tensor = tensor1 / tensor2  ## ou torch.div(tensor1, tensor2)\n",
        "\n",
        "print(mul_tensor)\n",
        "print(div_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xByE4M2RyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df5c9c6-6a57-417f-80a7-ceb9854e65bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma 1: tensor([[1.7137, 1.0873, 1.4926],\n",
            "        [0.4467, 0.2450, 0.3627],\n",
            "        [1.6761, 1.0450, 1.5414]])\n",
            "Forma 2: tensor([[1.7137, 1.0873, 1.4926],\n",
            "        [0.4467, 0.2450, 0.3627],\n",
            "        [1.6761, 1.0450, 1.5414]])\n"
          ]
        }
      ],
      "source": [
        "# Multiplicação Matricial sobre os tensores\n",
        "mul_mat_tensor1 = tensor1 @ tensor2.T  # Note: tensor2.T significa a transposição da matriz.\n",
        "mul_mat_tensor2 = torch.matmul(tensor1, tensor2.T)\n",
        "\n",
        "print(f\"Forma 1: {mul_mat_tensor1}\")\n",
        "print(f\"Forma 2: {mul_mat_tensor2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MAZ-DJhyoPI"
      },
      "source": [
        "## Datasets e Dataloaders\n",
        "\n",
        "Datasets são os conjuntos de dados utilizado para treinamento dos parametros dos modelos. Dataloaders são a estrutura para treinamento dos modelos no qual será feita a separação de dos *minibatchs*, eleatorização dos dados etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v7J8dHgPyoPJ"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas necessárias para essa seção\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc-rBXniyoPJ"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Esse exemplo faz o carregamento do dataset implementado na própria framework. Os dados utilizado aqui é o Fashion-MNIST. Outros datasets já implementados podem ser vistas em [Pytorch Dataset](https://pytorch.org/vision/stable/datasets.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EcE4lrz5yoPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f930b2f3-830e-4a86-c015-05da7034b25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12228863.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 204125.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3858902.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4170003.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Carregamento dos dados\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L9FZxdrWyoPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "67b47433-795b-4c20-9509-270ac796e37b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualização dos datasets\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3dm-dCfyoPJ"
      },
      "source": [
        "### Criando um Dataset customizável a partir de seus arquivos.\n",
        "\n",
        "Deve-se utilizar a class implementada no Pytorch (torch.utils.data.Dataset) e implementar três funções: *__init__*, *__len__* e *__getitem__*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Qc2-h3RXyoPJ"
      },
      "outputs": [],
      "source": [
        "# Exemplo de um Dataset customizado\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSdnvAQpyoPJ"
      },
      "source": [
        "### Preparação dos dados para treinamento.\n",
        "\n",
        "Após os datasets serem construídos, o próximo passo é montar o *dataloader*. No exemplo a seguir, utiliza-se a classe do Pytorch *torch.utils.data.DataLoader*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZLYJ-fCKyoPK"
      },
      "outputs": [],
      "source": [
        "# Construção dos dataloaders.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxVFrzxHyoPK"
      },
      "source": [
        "### Iterando sobre o DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EnE96VJ1yoPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "309d8cb4-d1bd-45f7-e282-be2e2b4b21ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 7\n"
          ]
        }
      ],
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeWxrDF3yoPK"
      },
      "source": [
        "## Construindo a Rede Neural\n",
        "\n",
        "Esta seção sera descrito a construção das redes neurais, como camadas e blocos. Os blocos imploementados podem ser vistos em [torch.nn](https://pytorch.org/docs/stable/nn.html), todas sendo subclasses do [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "PqW7xkLPzIPE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy9gw_ZNyoPK"
      },
      "source": [
        "### Utilização do dispositivo de treinamento\n",
        "\n",
        "Deve-se utilizar para treinar os modelos *hardwares* que acelerem, como GPU ou MPS, caso ,ão possua, utilize a própria CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OflLRxsvyoPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f6aa21-4bfc-4156-cdb0-0a7dd009ab0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Identificando o dispositivo disponível para treino.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEUouO8yoPK"
      },
      "source": [
        "### Definição da Classe\n",
        "\n",
        "A classe que será a rede neural proposta deve ser uma subclasse de nn.Module e inicializa-se as camadas da rede a partir da função *__init__*. Após isso, deve ser implementada o método *forward*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QKYHUt_cyoPK"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VXG6hqBbyoPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41510705-943a-4fd5-ac10-e67fed2c35c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Transferindo a rede neural para o dispositivo disponível.\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "asp4BDoDyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc87eeab-9374-4870-ca69-20aa38bf01dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([6], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Exemplo do forward implementado\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qq-xvMXyoPL"
      },
      "source": [
        "### Camadas do modelo\n",
        "\n",
        "Utilizando uma imagem colorida, com entradas RGB, tem-se que as imagens tem a seguinte dimensão: 3x28x28 (CxHxW), no qual C é o número de canais, H a altura da imagem e W a largura da imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SHC0Pok2yoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc95d8ce-9fae-4b27-8808-030701ffeee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uma imagem com entrada RGB\n",
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "daEg_yjMyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5f7f97-c7b5-4a21-b9b2-e92bdd4027a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "# Flatten: Converte a imagem 28x28 para um array contínuo de 784 pixels.\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RLUaNi3byoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6a03c8-7d4d-4184-b6ef-fa3b142f74cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "# nn.Linear é a camada totalmente conectada, no qual aplica a transformação linear, armazenando peso e bias.\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Z7UjYKRHyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84be9df-8fe7-4e99-faea-6e5f4fdfa0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1436,  0.3165,  0.3147,  0.1701,  0.1114, -0.1879,  0.3238,  0.3498,\n",
            "          0.7599, -0.2912, -0.4448, -0.0470,  0.0236,  0.1132,  0.2041,  0.1580,\n",
            "          0.2839, -0.1214, -0.0516, -0.1594],\n",
            "        [ 0.5291,  0.2873,  0.3048,  0.0076, -0.0967, -0.0914,  0.5185,  0.0815,\n",
            "          0.5553, -0.2925, -0.0463, -0.1771,  0.3018,  0.0141, -0.0927,  0.0621,\n",
            "          0.1355, -0.0958, -0.0391,  0.2582],\n",
            "        [ 0.3037,  0.5097,  0.2503, -0.1488,  0.0596,  0.0542,  0.4611,  0.1446,\n",
            "          0.9404, -0.1071, -0.3035, -0.2966, -0.0564,  0.2503,  0.0550, -0.0550,\n",
            "         -0.0809, -0.3106,  0.1421, -0.1198]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1436, 0.3165, 0.3147, 0.1701, 0.1114, 0.0000, 0.3238, 0.3498, 0.7599,\n",
            "         0.0000, 0.0000, 0.0000, 0.0236, 0.1132, 0.2041, 0.1580, 0.2839, 0.0000,\n",
            "         0.0000, 0.0000],\n",
            "        [0.5291, 0.2873, 0.3048, 0.0076, 0.0000, 0.0000, 0.5185, 0.0815, 0.5553,\n",
            "         0.0000, 0.0000, 0.0000, 0.3018, 0.0141, 0.0000, 0.0621, 0.1355, 0.0000,\n",
            "         0.0000, 0.2582],\n",
            "        [0.3037, 0.5097, 0.2503, 0.0000, 0.0596, 0.0542, 0.4611, 0.1446, 0.9404,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.2503, 0.0550, 0.0000, 0.0000, 0.0000,\n",
            "         0.1421, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# nn.ReLU, aplica a função de ativação ReLU aos valores de saída da rede.\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "04tbHu4KyoPP"
      },
      "outputs": [],
      "source": [
        "# nn.Sequencial, é o módulo de no qual agrupa todos os módulos de forma sequencial.\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lzwsRwkWyoPQ"
      },
      "outputs": [],
      "source": [
        "# Softmax transforma os valores no intervalo (-inf, +inf) para escala [0, 1], representando a probablidade de cada classe e soma igual a 1.\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "v7O6ozDoyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404df00e-dc48-448f-be67-65f668b38665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0301,  0.0122,  0.0139,  ...,  0.0254,  0.0116, -0.0090],\n",
            "        [ 0.0220,  0.0042,  0.0316,  ..., -0.0119, -0.0020, -0.0247]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0046,  0.0065], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0165,  0.0076, -0.0348,  ..., -0.0435, -0.0100, -0.0077],\n",
            "        [ 0.0132, -0.0429,  0.0126,  ..., -0.0003, -0.0194, -0.0253]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0294, 0.0134], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0264, -0.0072, -0.0030,  ...,  0.0096, -0.0317,  0.0049],\n",
            "        [-0.0114,  0.0322,  0.0085,  ...,  0.0108, -0.0293, -0.0208]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0022,  0.0232], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Representando os parâmetros dos modelos.\n",
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8XeSkUiyoPQ"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Ao treinar as redes neurais, os algoritmos de retropropagação (bachpropagation) são utilizados para ajustar os parâmetros dos modelos de acordo com os gradientes da função de perda.\n",
        "\n",
        "Para computar os gradientes, o Pytorch possui uma ferramenta chamada torch.autograd, no qual computa os gradientes de qualquer gráfico computacional. O exemplo a seguir mostra a saída dos gradientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3iSceGZFyoPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # Tensor de entrada\n",
        "y = torch.zeros(3)  # Saída esperada\n",
        "w = torch.randn(5, 3, requires_grad=True) # Perceptron com 5 entradas e 3 saídas\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "S7xXJy3nyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf66dfe-3e99-41d7-9248-62771cb10b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7d8119edf4c0>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7d8119edd6f0>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pdvpWvQbyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095c6a14-b007-437d-8ffc-1ff457a1150b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2820, 0.0419, 0.0540],\n",
            "        [0.2820, 0.0419, 0.0540],\n",
            "        [0.2820, 0.0419, 0.0540],\n",
            "        [0.2820, 0.0419, 0.0540],\n",
            "        [0.2820, 0.0419, 0.0540]])\n",
            "tensor([0.2820, 0.0419, 0.0540])\n"
          ]
        }
      ],
      "source": [
        "# Computando os gradientes\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3XfSjJFyoPQ"
      },
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "Entendido os passos descritos anteriormente, agora deve-se treinar o modelo para ajustar os parâmetros e minimizar o erro associado as previsões.\n",
        "\n",
        "Recaptulando os códigos descritos anteriormente, temos:\n",
        "- O dataset que será utilizado, no caso Fashion MNIST;\n",
        "- O dataloader que fará os *minibatchs*\n",
        "- O modelo da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2OAM-BSYyoPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqbC1e7IyoPR"
      },
      "source": [
        "### Hiperparametros\n",
        "- **Number of Epochs** - Número de vezes que será iterado pelo dataset.\n",
        "- **Batch Size** - Número de dados utilizados em cada propagação da rede neural;\n",
        "- **Learning Rate** - Fator de aprendizado dos parâmetros dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TSqa5tQfyoPR"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idW8dRYMyoPR"
      },
      "source": [
        "### Treinamento\n",
        "\n",
        "Itera sobre os dados para convergir os parâmetros do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jrY03wXCyoPR"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Define o modelo para o modo de treinamento.\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Computa as previsões e a perda\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmvsimZryoPR"
      },
      "source": [
        "### Validação/Teste\n",
        "\n",
        "Itera sobre o dataset para avaliar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SHkyDD_gyoPR"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Define o modelo para o modo de avaliação.\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKvN6AqxyoPR"
      },
      "source": [
        "### Função de Perda\n",
        "\n",
        "Função definida para minimizar e, assim, avaliar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5Ojg2IbVyoPS"
      },
      "outputs": [],
      "source": [
        "# Função escolhida: CrossEntropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "masw9eemyoPS"
      },
      "source": [
        "### Otimizadores\n",
        "\n",
        "Processo de ajuste do modelo para reduzir o erro para cada passo do treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ODN6qcR8yoPS"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha0MG9LHyoPS"
      },
      "source": [
        "### Treinamento\n",
        "\n",
        "Agrupando todos os passos, temos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-GQUEAd6yoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f912ac9d-2dfc-4b91-c7d8-4863bbbd6c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303240  [   64/60000]\n",
            "loss: 2.290910  [ 6464/60000]\n",
            "loss: 2.266094  [12864/60000]\n",
            "loss: 2.259184  [19264/60000]\n",
            "loss: 2.243848  [25664/60000]\n",
            "loss: 2.216823  [32064/60000]\n",
            "loss: 2.217419  [38464/60000]\n",
            "loss: 2.180775  [44864/60000]\n",
            "loss: 2.174345  [51264/60000]\n",
            "loss: 2.151219  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.2%, Avg loss: 2.140097 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.155178  [   64/60000]\n",
            "loss: 2.145988  [ 6464/60000]\n",
            "loss: 2.072238  [12864/60000]\n",
            "loss: 2.091375  [19264/60000]\n",
            "loss: 2.047494  [25664/60000]\n",
            "loss: 1.984908  [32064/60000]\n",
            "loss: 2.009392  [38464/60000]\n",
            "loss: 1.925773  [44864/60000]\n",
            "loss: 1.929046  [51264/60000]\n",
            "loss: 1.864569  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.857812 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.902089  [   64/60000]\n",
            "loss: 1.873575  [ 6464/60000]\n",
            "loss: 1.733999  [12864/60000]\n",
            "loss: 1.778149  [19264/60000]\n",
            "loss: 1.680014  [25664/60000]\n",
            "loss: 1.632823  [32064/60000]\n",
            "loss: 1.645348  [38464/60000]\n",
            "loss: 1.548530  [44864/60000]\n",
            "loss: 1.575868  [51264/60000]\n",
            "loss: 1.473647  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 1.491016 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.570226  [   64/60000]\n",
            "loss: 1.538425  [ 6464/60000]\n",
            "loss: 1.368080  [12864/60000]\n",
            "loss: 1.447395  [19264/60000]\n",
            "loss: 1.329440  [25664/60000]\n",
            "loss: 1.332697  [32064/60000]\n",
            "loss: 1.336332  [38464/60000]\n",
            "loss: 1.264529  [44864/60000]\n",
            "loss: 1.307497  [51264/60000]\n",
            "loss: 1.210678  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.4%, Avg loss: 1.235429 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.321519  [   64/60000]\n",
            "loss: 1.308234  [ 6464/60000]\n",
            "loss: 1.122760  [12864/60000]\n",
            "loss: 1.237739  [19264/60000]\n",
            "loss: 1.106776  [25664/60000]\n",
            "loss: 1.141872  [32064/60000]\n",
            "loss: 1.151334  [38464/60000]\n",
            "loss: 1.094027  [44864/60000]\n",
            "loss: 1.141753  [51264/60000]\n",
            "loss: 1.060304  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.3%, Avg loss: 1.078800 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.155785  [   64/60000]\n",
            "loss: 1.165356  [ 6464/60000]\n",
            "loss: 0.962707  [12864/60000]\n",
            "loss: 1.106473  [19264/60000]\n",
            "loss: 0.970907  [25664/60000]\n",
            "loss: 1.013435  [32064/60000]\n",
            "loss: 1.038387  [38464/60000]\n",
            "loss: 0.987722  [44864/60000]\n",
            "loss: 1.033625  [51264/60000]\n",
            "loss: 0.966404  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.9%, Avg loss: 0.977536 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.039496  [   64/60000]\n",
            "loss: 1.072214  [ 6464/60000]\n",
            "loss: 0.852868  [12864/60000]\n",
            "loss: 1.018266  [19264/60000]\n",
            "loss: 0.885060  [25664/60000]\n",
            "loss: 0.922067  [32064/60000]\n",
            "loss: 0.964323  [38464/60000]\n",
            "loss: 0.919024  [44864/60000]\n",
            "loss: 0.958598  [51264/60000]\n",
            "loss: 0.902453  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.2%, Avg loss: 0.907792 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.953662  [   64/60000]\n",
            "loss: 1.006334  [ 6464/60000]\n",
            "loss: 0.773731  [12864/60000]\n",
            "loss: 0.954967  [19264/60000]\n",
            "loss: 0.827004  [25664/60000]\n",
            "loss: 0.853996  [32064/60000]\n",
            "loss: 0.911724  [38464/60000]\n",
            "loss: 0.872624  [44864/60000]\n",
            "loss: 0.903996  [51264/60000]\n",
            "loss: 0.855413  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.2%, Avg loss: 0.856887 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.887608  [   64/60000]\n",
            "loss: 0.955968  [ 6464/60000]\n",
            "loss: 0.714043  [12864/60000]\n",
            "loss: 0.907079  [19264/60000]\n",
            "loss: 0.784837  [25664/60000]\n",
            "loss: 0.802054  [32064/60000]\n",
            "loss: 0.871453  [38464/60000]\n",
            "loss: 0.839682  [44864/60000]\n",
            "loss: 0.862377  [51264/60000]\n",
            "loss: 0.818836  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.7%, Avg loss: 0.817745 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.834516  [   64/60000]\n",
            "loss: 0.915062  [ 6464/60000]\n",
            "loss: 0.666958  [12864/60000]\n",
            "loss: 0.869431  [19264/60000]\n",
            "loss: 0.752203  [25664/60000]\n",
            "loss: 0.761419  [32064/60000]\n",
            "loss: 0.838667  [38464/60000]\n",
            "loss: 0.814996  [44864/60000]\n",
            "loss: 0.829762  [51264/60000]\n",
            "loss: 0.788964  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 0.786377 \n",
            "\n",
            "Fim!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Fim!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSto3oO-yoPS"
      },
      "source": [
        "## Salvar e Carregar os pesos dos modelos\n",
        "\n",
        "Nesta seção será descrita o salvamento de carregamento do modelo desejado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ED7uPRqwyoPS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "J6rCGfcpyoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2af54f4-a05b-4d4a-9eed-5d249343a30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 83.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Carregando pesos pré-treinados:\n",
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model.state_dict(), 'model_weights.pth')  # Salvando o modelo na máquina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "A_-XHpp4yoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f24e3d-d086-46e5-f82a-459fc9c9fe9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Carregando modelo salvo na maquina:\n",
        "model = models.vgg16() # Pesos não especificado\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}